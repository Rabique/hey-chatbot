#!/usr/bin/env python
# coding: utf-8

# In[1]:


get_ipython().system('pip install gradio==5.0.1')
get_ipython().system('pip install openai')
get_ipython().system('pip install langchain')
get_ipython().system('pip install pypdf')


# In[2]:


from dotenv import load_dotenv
load_dotenv()


# In[3]:


# openai APIí‚¤ ë“±ë¡
from openai import OpenAI
#from google.colab import userdata
import os

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
#os.environ["OPENAI_API_KEY"] = userdata.get('OPENAI_API_KEY')


# # 8-1 ìƒë‹´ë´‡ ì—…ê·¸ë ˆì´ë“œ

# In[4]:


import gradio as gr

from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.schema import AIMessage, HumanMessage, SystemMessage


# LLMê³¼ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
llm = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo')
memory = ConversationBufferMemory()
conversation = ConversationChain(
    llm=llm,
    memory=memory)


# ìƒë‹´ë´‡ - ì±„íŒ… ë° ë‹µë³€
def counseling_bot_chat(message, chat_history):
    if message == "":
        return "", chat_history
    else:
        result_message = ""
        if len(chat_history) <= 1:
            messages = [
                SystemMessage(content="ë‹¹ì‹ ì€ í—¤ì´ë§ˆíŠ¸ì˜ ìƒë‹´ì›ì…ë‹ˆë‹¤. ë§ˆíŠ¸ ìƒí’ˆê³¼ ê´€ë ¨ë˜ì§€ ì•Šì€ ì§ˆë¬¸ì—ëŠ” ì •ì¤‘íˆ ê±°ì ˆí•˜ì„¸ìš”."),
                AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”, í—¤ì´ë§ˆíŠ¸ì…ë‹ˆë‹¤. ìƒë‹´ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."),
                HumanMessage(content=message)
            ]
            result_message = conversation.predict(input=messages)
        else:
            result_message = conversation.predict(input=message)

        chat_history.append([message, result_message])
        return "", chat_history

# ìƒë‹´ë´‡ - ë˜ëŒë¦¬ê¸°
def counseling_bot_undo(chat_history):
    if len(chat_history) > 1:
        chat_history.pop()
    return chat_history

# ìƒë‹´ë´‡ - ì´ˆê¸°í™”
def counseling_bot_reset(chat_history):
    chat_history = [[None, "ì•ˆë…•í•˜ì„¸ìš”, í—¤ì´ë§ˆíŠ¸ì…ë‹ˆë‹¤. ìƒë‹´ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."]]
    return chat_history


# ë²ˆì—­ë´‡
def translate_bot(output_conditions, output_language, input_text):
    if input_text == "":
        return ""
    else:
        if output_conditions == "":
            output_conditions = ""
        else:
            output_conditions = "ë²ˆì—­í•  ë•Œì˜ ì¡°ê±´ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. " + output_conditions

        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì…ë ¥í•œ ì–¸ì–´ë¥¼ ë‹¤ë¥¸ ì„¤ëª…ì—†ì´ ê³§ë°”ë¡œ {0}ë¡œ ë²ˆì—­í•´ì„œ ì•Œë ¤ ì£¼ì„¸ìš”. ë²ˆì—­ì´ ë¶ˆê°€ëŠ¥í•œ ì–¸ì–´ë¼ë©´ ë²ˆì—­ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤ê³  ë§í•œ í›„ ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”. {1}".format(output_language, output_conditions)},
                {"role": "user", "content": input_text}
            ])

        return completion.choices[0].message.content


# ì†Œì„¤ë´‡
def novel_bot(model, temperature, detail):
    completion = client.chat.completions.create(
        model=model,
        temperature=temperature,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì†Œì„¤ê°€ì…ë‹ˆë‹¤. ìš”ì²­í•˜ëŠ” ì¡°ê±´ì— ë§ì¶° ì†Œì„¤ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."},
            {"role": "user", "content": detail}
        ])
    return completion.choices[0].message.content


# ë ˆì´ì•„ì›ƒ
with gr.Blocks(theme=gr.themes.Default()) as app:
    with gr.Tab("ìƒë‹´ë´‡"):
        #1
        gr.Markdown(
            value="""
            # <center>ìƒë‹´ë´‡</center>
            <center>í—¤ì´ë§ˆíŠ¸ ìƒë‹´ ë´‡ì…ë‹ˆë‹¤. ë§ˆíŠ¸ì—ì„œ íŒë§¤í•˜ëŠ” ìƒí’ˆê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì— ë‹µë³€ë“œë¦½ë‹ˆë‹¤.</center>
            """)
        #2
        cb_chatbot = gr.Chatbot(
            value=[[None, "ì•ˆë…•í•˜ì„¸ìš”, í—¤ì´ë§ˆíŠ¸ì…ë‹ˆë‹¤. ìƒë‹´ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."]],
            show_label=False
        )
        with gr.Row():
            #3
            cb_user_input = gr.Text(
                lines=1,
                placeholder="ì…ë ¥ ì°½",
                container=False,
                scale=9
            )
            #4
            cb_send_btn = gr.Button(
                value="ë³´ë‚´ê¸°",
                scale=1,
                variant="primary",
                icon="https://cdn-icons-png.flaticon.com/128/12439/12439334.png"
            )
        with gr.Row():
            #5
            gr.Button(value="â†©ï¸ ë˜ëŒë¦¬ê¸°").click(fn=counseling_bot_undo, inputs=cb_chatbot, outputs=cb_chatbot)
            #6
            gr.Button(value="ğŸ”„ï¸ ì´ˆê¸°í™”").click(fn=counseling_bot_reset, inputs=cb_chatbot, outputs=cb_chatbot)
        # ë³´ë‚´ê¸°1
        cb_send_btn.click(fn=counseling_bot_chat, inputs=[cb_user_input, cb_chatbot], outputs=[cb_user_input, cb_chatbot])
        # ë³´ë‚´ê¸°2
        cb_user_input.submit(fn=counseling_bot_chat, inputs=[cb_user_input, cb_chatbot], outputs=[cb_user_input, cb_chatbot])

    with gr.Tab("ë²ˆì—­ë´‡"):
        #1
        gr.Markdown(
            value="""
            # <center>ë²ˆì—­ë´‡</center>
            <center>ë‹¤êµ­ì–´ ë²ˆì—­ë´‡ì…ë‹ˆë‹¤.</center>
            """)
        with gr.Row():
            #2
            tb_output_conditions = gr.Text(
                label="ë²ˆì—­ ì¡°ê±´",
                placeholder="ì˜ˆì‹œ: ìì—°ìŠ¤ëŸ½ê²Œ",
                lines=1,
                max_lines=3
            )
            #3
            tb_output_language = gr.Dropdown(
                label="ì¶œë ¥ ì–¸ì–´",
                choices=["í•œêµ­ì–´", "ì˜ì–´", "ì¼ë³¸ì–´", "ì¤‘êµ­ì–´"],
                value="í•œêµ­ì–´",
                allow_custom_value=True,
                interactive=True
            )
        #4
        tb_submit = gr.Button(
            value="ë²ˆì—­í•˜ê¸°",
            variant="primary"
        )
        with gr.Row():
            #5
            tb_input_text = gr.Text(
                placeholder="ë²ˆì—­í•  ë‚´ìš©ì„ ì ì–´ì£¼ì„¸ìš”.",
                lines=10,
                max_lines=20,
                show_copy_button=True,
                label=""
            )
            #6
            tb_output_text = gr.Text(
                lines=10,
                max_lines=20,
                show_copy_button=True,
                label="",
                interactive=False
            )
        # ë²ˆì—­ë´‡ ë‚´ìš© ë³´ë‚´ê¸°
        tb_submit.click(
            fn=translate_bot,
            inputs=[tb_output_conditions,
                tb_output_language,
                tb_input_text],
            outputs=tb_output_text
        )

    with gr.Tab("ì†Œì„¤ë´‡"):
        #1
        gr.Markdown(
            value="""
            # <center>ì†Œì„¤ë´‡</center>
            <center>ì†Œì„¤ì„ ìƒì„±í•´ì£¼ëŠ” ë´‡ì…ë‹ˆë‹¤.</center>
            """)
        with gr.Accordion(label="ì‚¬ìš©ì ì„¤ì •"):
            with gr.Row():
                with gr.Column(scale=1):
                    #2
                    nb_model = gr.Dropdown(
                        label="ëª¨ë¸ ì„ íƒ",
                        choices=["gpt-3.5-turbo", "gpt-3.5-turbo-16k", "gpt-4", "gpt-4-32k", "gpt-4-1106-preview"],
                        value="gpt-4-1106-preview",
                        interactive=True
                    )
                    #3
                    nb_temperature = gr.Slider(
                        label="ì°½ì˜ì„±",
                        info="ìˆ«ìê°€ ë†’ì„ ìˆ˜ë¡ ì°½ì˜ì ",
                        minimum=0,
                        maximum=2,
                        step=0.1,
                        value=1,
                        interactive=True
                    )
                #4
                nb_detail = gr.Text(
                    container=False,
                    placeholder="ì†Œì„¤ì˜ ì„¸ë¶€ì ì¸ ì„¤ì •ì„ ì‘ì„±í•©ë‹ˆë‹¤.",
                    lines=8,
                    scale=4
                )
        #5
        nb_submit = gr.Button(
            value="ìƒì„±í•˜ê¸°",
            variant="primary"
        )
        #6
        nb_output = gr.Text(
            label="",
            placeholder="ì´ê³³ì— ì†Œì„¤ì˜ ë‚´ìš©ì´ ì¶œë ¥ë©ë‹ˆë‹¤.",
            lines=10,
            max_lines=200,
            show_copy_button=True
        )
        # ë³´ë‚´ê¸°
        nb_submit.click(
            fn=novel_bot,
            inputs=[nb_model, nb_temperature, nb_detail],
            outputs=nb_output
        )

app.launch(share=True)


# # 8-2 ë²ˆì—­ë´‡ ì—…ê·¸ë ˆì´ë“œ

# In[6]:


import gradio as gr

from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.schema import AIMessage, HumanMessage, SystemMessage

from langchain.document_loaders import TextLoader
from langchain.document_loaders import PyPDFLoader


# LLMê³¼ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
llm = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo')
memory = ConversationBufferMemory()
conversation = ConversationChain(
    llm=llm,
    memory=memory)


# ìƒë‹´ë´‡ - ì±„íŒ… ë° ë‹µë³€
def counseling_bot_chat(message, chat_history):
    if message == "":
        return "", chat_history
    else:
        result_message = ""
        if len(chat_history) <= 1:
            messages = [
                SystemMessage(content="ë‹¹ì‹ ì€ í—¤ì´ë§ˆíŠ¸ì˜ ìƒë‹´ì›ì…ë‹ˆë‹¤. ë§ˆíŠ¸ ìƒí’ˆê³¼ ê´€ë ¨ë˜ì§€ ì•Šì€ ì§ˆë¬¸ì—ëŠ” ì •ì¤‘íˆ ê±°ì ˆí•˜ì„¸ìš”."),
                AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”, í—¤ì´ë§ˆíŠ¸ì…ë‹ˆë‹¤. ìƒë‹´ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."),
                HumanMessage(content=message)
            ]
            result_message = conversation.predict(input=messages)
        else:
            result_message = conversation.predict(input=message)

        chat_history.append([message, result_message])
        return "", chat_history

# ìƒë‹´ë´‡ - ë˜ëŒë¦¬ê¸°
def counseling_bot_undo(chat_history):
    if len(chat_history) > 1:
        chat_history.pop()
    return chat_history

# ìƒë‹´ë´‡ - ì´ˆê¸°í™”
def counseling_bot_reset(chat_history):
    chat_history = [[None, "ì•ˆë…•í•˜ì„¸ìš”, í—¤ì´ë§ˆíŠ¸ì…ë‹ˆë‹¤. ìƒë‹´ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."]]
    return chat_history


# ë²ˆì—­ë´‡
def translate_bot(output_conditions, output_language, input_text):
    if input_text == "":
        return ""
    else:
        if output_conditions == "":
            output_conditions = ""
        else:
            output_conditions = "ë²ˆì—­í•  ë•Œì˜ ì¡°ê±´ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. " + output_conditions

        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì…ë ¥í•œ ì–¸ì–´ë¥¼ ë‹¤ë¥¸ ì„¤ëª…ì—†ì´ ê³§ë°”ë¡œ {0}ë¡œ ë²ˆì—­í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”. ë²ˆì—­ì´ ë¶ˆê°€ëŠ¥í•œ ì–¸ì–´ë¼ë©´ ë²ˆì—­ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤ê³  ë§í•œ í›„ ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”. {1}".format(output_language, output_conditions)},
                {"role": "user", "content": input_text}
            ])

        return completion.choices[0].message.content

# ë²ˆì—­ë´‡ - Textì—…ë¡œë“œ
def translate_bot_Text_upload(files):
    loader = TextLoader(files)
    document = loader.load()
    return document[0].page_content

# ë²ˆì—­ë´‡ - PDFì—…ë¡œë“œ
def translate_bot_PDF_upload(files):
    loader = PyPDFLoader(files)
    pages = loader.load_and_split()
    return pages[0].page_content


# ì†Œì„¤ë´‡
def novel_bot(model, temperature, detail):
    completion = client.chat.completions.create(
        model=model,
        temperature=temperature,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì†Œì„¤ê°€ì…ë‹ˆë‹¤. ìš”ì²­í•˜ëŠ” ì¡°ê±´ì— ë§ì¶° ì†Œì„¤ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."},
            {"role": "user", "content": detail}
        ])
    return completion.choices[0].message.content


# ë ˆì´ì•„ì›ƒ
with gr.Blocks(theme=gr.themes.Default()) as app:
    with gr.Tab("ìƒë‹´ë´‡"):
        #1
        gr.Markdown(
            value="""
            # <center>ìƒë‹´ë´‡</center>
            <center>í—¤ì´ë§ˆíŠ¸ ìƒë‹´ ë´‡ì…ë‹ˆë‹¤. ë§ˆíŠ¸ì—ì„œ íŒë§¤í•˜ëŠ” ìƒí’ˆê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì— ë‹µë³€ë“œë¦½ë‹ˆë‹¤.</center>
            """)
        #2
        cb_chatbot = gr.Chatbot(
            value=[[None, "ì•ˆë…•í•˜ì„¸ìš”, í—¤ì´ë§ˆíŠ¸ì…ë‹ˆë‹¤. ìƒë‹´ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."]],
            show_label=False
        )
        with gr.Row():
            #3
            cb_user_input = gr.Text(
                lines=1,
                placeholder="ì…ë ¥ ì°½",
                container=False,
                scale=9
            )
            #4
            cb_send_btn = gr.Button(
                value="ë³´ë‚´ê¸°",
                scale=1,
                variant="primary",
                icon="https://cdn-icons-png.flaticon.com/128/12439/12439334.png"
            )
        with gr.Row():
            #5
            gr.Button(value="â†©ï¸ ë˜ëŒë¦¬ê¸°").click(fn=counseling_bot_undo, inputs=cb_chatbot, outputs=cb_chatbot)
            #6
            gr.Button(value="ğŸ”„ï¸ ì´ˆê¸°í™”").click(fn=counseling_bot_reset, inputs=cb_chatbot, outputs=cb_chatbot)
        # ë³´ë‚´ê¸°1
        cb_send_btn.click(fn=counseling_bot_chat, inputs=[cb_user_input, cb_chatbot], outputs=[cb_user_input, cb_chatbot])
        # ë³´ë‚´ê¸°2
        cb_user_input.submit(fn=counseling_bot_chat, inputs=[cb_user_input, cb_chatbot], outputs=[cb_user_input, cb_chatbot])

    with gr.Tab("ë²ˆì—­ë´‡"):
        #1
        gr.Markdown(
            value="""
            # <center>ë²ˆì—­ë´‡</center>
            <center>ë‹¤êµ­ì–´ ë²ˆì—­ ë´‡ì…ë‹ˆë‹¤.</center>
            """)
        with gr.Row():
            #2
            tb_output_conditions = gr.Text(
                label="ë²ˆì—­ ì¡°ê±´",
                placeholder="ì˜ˆì‹œ: ìì—°ìŠ¤ëŸ½ê²Œ",
                lines=1,
                max_lines=3
            )
            #3
            tb_output_language = gr.Dropdown(
                label="ì¶œë ¥ ì–¸ì–´",
                choices=["í•œêµ­ì–´", "ì˜ì–´", "ì¼ë³¸ì–´", "ì¤‘êµ­ì–´"],
                value="í•œêµ­ì–´",
                allow_custom_value=True,
                interactive=True
            )
        with gr.Row():
            #7
            tb_TXTupload = gr.UploadButton(label="ğŸ“„ Txt ì—…ë¡œë“œ")
            #8
            tb_PDFupload = gr.UploadButton(label="ğŸ“¤ PDF ì—…ë¡œë“œ")
        #4
        tb_submit = gr.Button(
            value="ë²ˆì—­í•˜ê¸°",
            variant="primary"
        )
        with gr.Row():
            #5
            tb_input_text = gr.Text(
                placeholder="ë²ˆì—­í•  ë‚´ìš©ì„ ì ì–´ì£¼ì„¸ìš”.",
                lines=10,
                max_lines=20,
                show_copy_button=True,
                label=""
            )
            #6
            tb_output_text = gr.Text(
                lines=10,
                max_lines=20,
                show_copy_button=True,
                label="",
                interactive=False
            )
        # ë³´ë‚´ê¸°
        tb_submit.click(
            fn=translate_bot,
            inputs=[tb_output_conditions,
                    tb_output_language,
                    tb_input_text],
            outputs=tb_output_text
        )
        # TextíŒŒì¼ ì—…ë¡œë“œ
        tb_TXTupload.upload(
            fn=translate_bot_Text_upload,
            inputs=tb_TXTupload,
            outputs=tb_input_text
        )
        # PDFíŒŒì¼ ì—…ë¡œë“œ
        tb_PDFupload.upload(
            fn=translate_bot_PDF_upload,
            inputs=tb_PDFupload,
            outputs=tb_input_text
        )

    with gr.Tab("ì†Œì„¤ë´‡"):
        #1
        gr.Markdown(
            value="""
            # <center>ì†Œì„¤ë´‡</center>
            <center>ì†Œì„¤ì„ ìƒì„±í•´ì£¼ëŠ” ë´‡ì…ë‹ˆë‹¤.</center>
            """)
        with gr.Accordion(label="ì‚¬ìš©ì ì„¤ì •"):
            with gr.Row():
                with gr.Column(scale=1):
                    #2
                    nb_model = gr.Dropdown(
                        label="ëª¨ë¸ ì„ íƒ",
                        choices=["gpt-3.5-turbo", "gpt-3.5-turbo-16k", "gpt-4", "gpt-4-32k", "gpt-4-1106-preview"],
                        value="gpt-4-1106-preview",
                        interactive=True
                    )
                    #3
                    nb_temperature = gr.Slider(
                        label="ì°½ì˜ì„±",
                        info="ìˆ«ìê°€ ë†’ì„ ìˆ˜ë¡ ì°½ì˜ì ",
                        minimum=0,
                        maximum=2,
                        step=0.1,
                        value=1,
                        interactive=True
                    )
                #4
                nb_detail = gr.Text(
                    container=False,
                    placeholder="ì†Œì„¤ì˜ ì„¸ë¶€ì ì¸ ì„¤ì •ì„ ì‘ì„±í•©ë‹ˆë‹¤.",
                    lines=8,
                    scale=4
                )
        #5
        nb_submit = gr.Button(
            value="ìƒì„±í•˜ê¸°",
            variant="primary"
        )
        #6
        nb_output = gr.Text(
            label="",
            placeholder="ì´ê³³ì— ì†Œì„¤ì˜ ë‚´ìš©ì´ ì¶œë ¥ë©ë‹ˆë‹¤.",
            lines=10,
            max_lines=200,
            show_copy_button=True
        )
        # ë³´ë‚´ê¸°
        nb_submit.click(
            fn=novel_bot,
            inputs=[nb_model, nb_temperature, nb_detail],
            outputs=nb_output
        )

app.launch()

